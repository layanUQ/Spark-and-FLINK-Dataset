//Who are the top six publishers with the highest number of publications in the dataset?

scala>  spark.conf.set("spark.sql.legacy.timeParserPolicy", "LEGACY")

scala> import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.SparkSession

scala> import org.apache.spark.sql.functions._
import org.apache.spark.sql.functions._

scala> val spark = SparkSession.builder().appName("Arabic News Analysis").getOrCreate()
24/10/17 19:31:09 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.
spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@4f1a6259
scala> val columns = Seq("requested_url", "plain_text", "published_date", "title", "tags", "categories", "author", "sitename", "image_url", "language", "language_score", "responded_url", "publisher", "warc_path", "crawl_date")
columns: Seq[String] = List(requested_url, plain_text, published_date, title, tags, categories, author, sitename, image_url, language, language_score, responded_url, publisher, warc_path, crawl_date)

scala> val df = spark.read.option("header", "true").option("inferSchema", "false").csv("C:\\Users\\96659\\Desktop\\ccnews\\data_gathered\\arabic_ccnews_partial.csv").toDF(columns: _*)
df: org.apache.spark.sql.DataFrame = [requested_url: string, plain_text: string ... 13 more fields]

scala>

scala> val df_cleaned = df.select("published_date", "publisher").filter(col("published_date").isNotNull && col("published_date") =!= "").filter(to_date(col("published_date"), "yyyy-MM-dd").isNotNull)
df_cleaned: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [published_date: string, publisher: string]

scala> val publisher_trends = df_cleaned.withColumn("year", year(to_date(col("published_date"), "yyyy-MM-dd"))).groupBy("publisher").agg(count("publisher").alias("article_count"))
publisher_trends: org.apache.spark.sql.DataFrame = [publisher: string, article_count: bigint]

scala>  val top_publishers = publisher_trends.orderBy(col("article_count").desc).limit(15)
top_publishers: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [publisher: string, article_count: bigint]

scala> top_publishers.show()
